{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "847acd88",
   "metadata": {},
   "source": [
    "## Evaluate Presidio Analyzer using the Presidio Evaluator framework\n",
    "\n",
    "This notebook demonstrates how to evaluate a Presidio instance using the presidio-evaluator framework\n",
    "Steps:\n",
    "1. Load dataset from file\n",
    "2. Simple dataset statistics\n",
    "3. Define the AnalyzerEngine object (and its parameters)\n",
    "4. Align the dataset's entities to Presidio's entities\n",
    "5. Set up the Evaluator object\n",
    "6. Run experiment\n",
    "7. Evaluate results\n",
    "8. Error analysis\n",
    "\n",
    "For an example with a custom Presidio instance, see [notebook 5](5_Evaluate_Custom_Presidio_Analyzer.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b946feda",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T08:51:55.393735Z",
     "start_time": "2024-10-07T08:51:55.390376Z"
    }
   },
   "outputs": [],
   "source": [
    "# install presidio evaluator via pip if not yet installed\n",
    "\n",
    "#!pip install presidio-evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae85cae9",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-10-07T08:51:55.407621Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stanza and spacy_stanza are not installed\n",
      "Flair is not installed by default\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "from collections import Counter\n",
    "from typing import Dict, List\n",
    "import json\n",
    "\n",
    "from presidio_evaluator import InputSample\n",
    "from presidio_evaluator.evaluation import Evaluator, ModelError, Plotter\n",
    "from presidio_evaluator.experiment_tracking import get_experiment_tracker\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736fdd23",
   "metadata": {},
   "source": [
    "## 1. Load dataset from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4cbd55c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-19T19:00:06.630016Z",
     "start_time": "2024-09-19T18:59:59.587398Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizing input:   0%|          | 0/153 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model en_core_web_sm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizing input: 100%|██████████| 153/153 [00:01<00:00, 108.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"generated_size_500_date_August_04_2025.json\"\n",
    "dataset = InputSample.read_dataset_json(Path(Path.cwd().parent, \"data\", dataset_name))\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53077517d947cfa",
   "metadata": {},
   "source": [
    "This dataset was auto generated. See more info here [Synthetic data generation](1_Generate_data.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c164ea07",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-19T19:00:06.700573Z",
     "start_time": "2024-09-19T19:00:06.642617Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_entity_counts(dataset: List[InputSample]) -> Dict:\n",
    "    \"\"\"Return a dictionary with counter per entity type.\"\"\"\n",
    "    entity_counter = Counter()\n",
    "    for sample in dataset:\n",
    "        for tag in sample.tags:\n",
    "            entity_counter[tag] += 1\n",
    "    return entity_counter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d127b576-b19f-4ba9-b434-16332d9f5f2a",
   "metadata": {},
   "source": [
    "## 2. Simple dataset statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77aedae6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-19T19:00:06.780286Z",
     "start_time": "2024-09-19T19:00:06.720020Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count per entity:\n",
      "[('O', 1356), ('PERSON', 433), ('HOSPITAL_NAME', 303), ('DATE_TIME', 295),\n",
      " ('DRUG', 49), ('FREQUENCY', 37), ('TIME', 36), ('DOSE', 23), ('DURATION', 13),\n",
      " ('SYMPTOM', 5), ('PHONE_NUMBER', 5), ('LAB_RESULT', 4),\n",
      " ('MEDICAL_CONDITION', 4), ('PROCEDURE', 3), ('LOCATION', 2), ('PATIENT_ID', 1),\n",
      " ('INSURANCE_NUMBER', 1), ('BLOOD_PRESSURE', 1)]\n",
      "\n",
      "Min and max number of tokens in dataset: Min: 7, Max: 27\n",
      "Min and max sentence length in dataset: Min: 30, Max: 138\n",
      "\n",
      "Example InputSample:\n",
      "Full text: Dr. John Doe recommended MRI for further evaluation of Headache.\n",
      "Spans: [Span(type: SYMPTOM, value: Headache, char_span: [55: 63]), Span(type: PROCEDURE, value: MRI, char_span: [25: 28]), Span(type: PERSON, value: John Doe, char_span: [4: 12])]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "entity_counts = get_entity_counts(dataset)\n",
    "print(\"Count per entity:\")\n",
    "pprint(entity_counts.most_common(), compact=True)\n",
    "\n",
    "print(\"\\nMin and max number of tokens in dataset: \"\\\n",
    "f\"Min: {min([len(sample.tokens) for sample in dataset])}, \"\\\n",
    "f\"Max: {max([len(sample.tokens) for sample in dataset])}\")\n",
    "\n",
    "print(f\"Min and max sentence length in dataset: \" \\\n",
    "f\"Min: {min([len(sample.full_text) for sample in dataset])}, \"\\\n",
    "f\"Max: {max([len(sample.full_text) for sample in dataset])}\")\n",
    "\n",
    "print(\"\\nExample InputSample:\")\n",
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6b6b4f3895023d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-19T19:00:06.847334Z",
     "start_time": "2024-09-19T19:00:06.791658Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A few examples sentences containing each entity:\n",
      "\n",
      "Entity: <PERSON> two example sentences:\n",
      "\n",
      "1) Dr. John Doe recommended MRI for further evaluation of Headache.\n",
      "2) Appointment for John Doe confirmed at St. Luke's Cornwall Hospital on 2025-08-01 at 10:00.\n",
      "------------------------------------\n",
      "\n",
      "Entity: <PROCEDURE> two example sentences:\n",
      "\n",
      "1) Dr. John Doe recommended MRI for further evaluation of Headache.\n",
      "2) John Doe was admitted for Hypertension and underwent MRI on 2025-08-01.\n",
      "------------------------------------\n",
      "\n",
      "Entity: <SYMPTOM> two example sentences:\n",
      "\n",
      "1) Dr. John Doe recommended MRI for further evaluation of Headache.\n",
      "2) John Doe was advised to monitor Headache and return if symptoms worsen.\n",
      "------------------------------------\n",
      "\n",
      "Entity: <HOSPITAL_NAME> two example sentences:\n",
      "\n",
      "1) Appointment for John Doe confirmed at St. Luke's Cornwall Hospital on 2025-08-01 at 10:00.\n",
      "2) Reminder: John Doe has an appointment with Dr. Ryan Thomas at Pine Rest Christian Mental Health Services on 2025-08-01.\n",
      "------------------------------------\n",
      "\n",
      "Entity: <DATE_TIME> two example sentences:\n",
      "\n",
      "1) Appointment for John Doe confirmed at St. Luke's Cornwall Hospital on 2025-08-01 at 10:00.\n",
      "2) Reminder: John Doe has an appointment with Dr. Ryan Thomas at Pine Rest Christian Mental Health Services on 2025-08-01.\n",
      "------------------------------------\n",
      "\n",
      "Entity: <TIME> two example sentences:\n",
      "\n",
      "1) Appointment for John Doe confirmed at St. Luke's Cornwall Hospital on 2025-08-01 at 10:00.\n",
      "2) Follow-up appointment for John Doe is scheduled on 2025-08-01 at 10:00 at Cumberland Hospital.\n",
      "------------------------------------\n",
      "\n",
      "Entity: <LAB_RESULT> two example sentences:\n",
      "\n",
      "1) Blood glucose level for John Doe is Normal.\n",
      "2) CBC for John Doe shows Normal.\n",
      "------------------------------------\n",
      "\n",
      "Entity: <DRUG> two example sentences:\n",
      "\n",
      "1) Please refill Ibuprofen for John Doe. Current dosage: 75 mg.\n",
      "2) Discontinue Ibuprofen due to adverse reaction in John Doe.\n",
      "------------------------------------\n",
      "\n",
      "Entity: <DOSE> two example sentences:\n",
      "\n",
      "1) Please refill Ibuprofen for John Doe. Current dosage: 75 mg.\n",
      "2) Prescription for John Doe: Ibuprofen, 250 mg, to be taken as needed for 10 days.\n",
      "------------------------------------\n",
      "\n",
      "Entity: <FREQUENCY> two example sentences:\n",
      "\n",
      "1) Prescription for John Doe: Ibuprofen, 250 mg, to be taken as needed for 10 days.\n",
      "2) Prescription for John Doe: Ibuprofen, 100 mg, to be taken at bedtime for 10 days.\n",
      "------------------------------------\n",
      "\n",
      "Entity: <DURATION> two example sentences:\n",
      "\n",
      "1) Prescription for John Doe: Ibuprofen, 250 mg, to be taken as needed for 10 days.\n",
      "2) Prescription for John Doe: Ibuprofen, 100 mg, to be taken at bedtime for 10 days.\n",
      "------------------------------------\n",
      "\n",
      "Entity: <MEDICAL_CONDITION> two example sentences:\n",
      "\n",
      "1) John Doe has a history of Hypertension and is currently taking Ibuprofen.\n",
      "2) John Doe was admitted for Hypertension and underwent MRI on 2025-08-01.\n",
      "------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"A few examples sentences containing each entity:\\n\")\n",
    "for entity in entity_counts.keys():\n",
    "    samples = [sample for sample in dataset if entity in set(sample.tags)]\n",
    "    if len(samples) > 1 and entity != \"O\":\n",
    "        print(f\"Entity: <{entity}> two example sentences:\\n\"\n",
    "              f\"\\n1) {samples[0].full_text}\"\n",
    "              f\"\\n2) {samples[1].full_text}\"\n",
    "              f\"\\n------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5e16cb-bee8-4f0a-a543-4879daa35b9e",
   "metadata": {},
   "source": [
    "## 3. Define the AnalyzerEngine object \n",
    "Using Presidio with default parameters (not recommended, it's used here for simplicity). For an example on customization, see [notebook 5](5_Evaluate_Custom_Presidio_Analyzer.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "967462f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import medspacy\n",
    "#nlp = medspacy.load(\"en_core_web_sm\")\n",
    "#print(nlp.pipe_names)  # Should include 'medspacy_ner'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "313b508f-e901-40b9-b575-c7fb8a794652",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-19T19:00:08.062842Z",
     "start_time": "2024-09-19T19:00:06.853338Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Supported entities for English:'\n",
      "['MEDICAL_CONDITION', 'DURATION', 'DOSAGE', 'LAB_TEST', 'VACCINE', 'CRYPTO',\n",
      " 'MEDICAL_LICENSE', 'LOCATION', 'EMAIL_ADDRESS', 'DRUG', 'US_BANK_NUMBER',\n",
      " 'US_PASSPORT', 'NRP', 'IBAN_CODE', 'US_DRIVER_LICENSE', 'ALLERGY', 'PROCEDURE',\n",
      " 'FREQUENCY', 'PERSON', 'DATE_TIME', 'ANATOMY', 'HOSPITAL', 'US_SSN', 'SYMPTOM',\n",
      " 'UK_NHS', 'URL', 'PHONE_NUMBER', 'US_ITIN', 'CREDIT_CARD', 'MEDICAL_DEVICE',\n",
      " 'IP_ADDRESS']\n",
      "\n",
      "Loaded recognizers for English:\n",
      "['CreditCardRecognizer', 'UsBankRecognizer', 'UsLicenseRecognizer',\n",
      " 'UsItinRecognizer', 'UsPassportRecognizer', 'UsSsnRecognizer', 'NhsRecognizer',\n",
      " 'CryptoRecognizer', 'DateRecognizer', 'EmailRecognizer', 'IbanRecognizer',\n",
      " 'IpRecognizer', 'MedicalLicenseRecognizer', 'PhoneRecognizer', 'UrlRecognizer',\n",
      " 'SpacyRecognizer', 'MedspacyRecognizer']\n",
      "\n",
      "Loaded NER models:\n",
      "[{'lang_code': 'en', 'model_name': 'en_core_web_lg'}]\n"
     ]
    }
   ],
   "source": [
    "from presidio_analyzer import AnalyzerEngine\n",
    "from presidio_analyzer.medspacy_recognizer import MedspacyRecognizer\n",
    "# Loading the vanilla Analyzer Engine, with the default NER model.\n",
    "analyzer_engine = AnalyzerEngine(default_score_threshold=0.4)\n",
    "medspacy_recognizer = MedspacyRecognizer()\n",
    "analyzer_engine.registry.add_recognizer(medspacy_recognizer)\n",
    "\n",
    "pprint(f\"Supported entities for English:\")\n",
    "pprint(analyzer_engine.get_supported_entities(\"en\"), compact=True)\n",
    "\n",
    "print(f\"\\nLoaded recognizers for English:\")\n",
    "pprint([rec.name for rec in analyzer_engine.registry.get_recognizers(\"en\", all_fields=True)], compact=True)\n",
    "\n",
    "print(f\"\\nLoaded NER models:\")\n",
    "pprint(analyzer_engine.nlp_engine.models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df451b86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa44f70a7c7aa3f0",
   "metadata": {},
   "source": [
    "## 4. Align the dataset's entities to Presidio's entities\n",
    "\n",
    "There is possibly a difference between the names of entities in the dataset, and the names of entities Presidio can detect.\n",
    "For example, it could be that a dataset labels a name as PER while Presidio returns PERSON. To be able to compare the predicted value to the actual and gather metrics, an alignment between the entity names is necessary. Consider changing the mapping if your dataset and/or Presidio instance supports difference entity types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff2e676f44f72e4e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-19T19:05:53.077036Z",
     "start_time": "2024-09-19T19:05:53.020399Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using this mapping between the dataset and Presidio's entities:\n",
      "{'ADDRESS': 'LOCATION',\n",
      " 'AGE': 'AGE',\n",
      " 'BIRTHDAY': 'DATE_TIME',\n",
      " 'CITY': 'LOCATION',\n",
      " 'CREDIT_CARD': 'CREDIT_CARD',\n",
      " 'CREDIT_CARD_NUMBER': 'CREDIT_CARD',\n",
      " 'DATE': 'DATE_TIME',\n",
      " 'DATE_OF_BIRTH': 'DATE_TIME',\n",
      " 'DATE_TIME': 'DATE_TIME',\n",
      " 'DOB': 'DATE_TIME',\n",
      " 'DOMAIN': 'URL',\n",
      " 'DOMAIN_NAME': 'URL',\n",
      " 'EMAIL': 'EMAIL_ADDRESS',\n",
      " 'EMAIL_ADDRESS': 'EMAIL_ADDRESS',\n",
      " 'FACILITY': 'LOCATION',\n",
      " 'FIRST_NAME': 'PERSON',\n",
      " 'GPE': 'LOCATION',\n",
      " 'HCW': 'PERSON',\n",
      " 'HOSP': 'ORGANIZATION',\n",
      " 'HOSPITAL': 'ORGANIZATION',\n",
      " 'IBAN': 'IBAN_CODE',\n",
      " 'IBAN_CODE': 'IBAN_CODE',\n",
      " 'ID': 'ID',\n",
      " 'IP_ADDRESS': 'IP_ADDRESS',\n",
      " 'LAST_NAME': 'PERSON',\n",
      " 'LOC': 'LOCATION',\n",
      " 'LOCATION': 'LOCATION',\n",
      " 'NAME': 'PERSON',\n",
      " 'NATIONALITY': 'NRP',\n",
      " 'NORP': 'NRP',\n",
      " 'NRP': 'NRP',\n",
      " 'O': 'O',\n",
      " 'ORG': 'ORGANIZATION',\n",
      " 'ORGANIZATION': 'ORGANIZATION',\n",
      " 'PATIENT': 'PERSON',\n",
      " 'PATORG': 'ORGANIZATION',\n",
      " 'PER': 'PERSON',\n",
      " 'PERSON': 'PERSON',\n",
      " 'PHONE': 'PHONE_NUMBER',\n",
      " 'PHONE_NUMBER': 'PHONE_NUMBER',\n",
      " 'PREFIX': 'TITLE',\n",
      " 'SSN': 'US_SSN',\n",
      " 'STAFF': 'PERSON',\n",
      " 'STREET_ADDRESS': 'LOCATION',\n",
      " 'TIME': 'DATE_TIME',\n",
      " 'TITLE': 'TITLE',\n",
      " 'URL': 'URL',\n",
      " 'US_DRIVER_LICENSE': 'US_DRIVER_LICENSE',\n",
      " 'US_SSN': 'US_SSN',\n",
      " 'VENDOR': 'ORGANIZATION',\n",
      " 'ZIP': 'ZIP_CODE',\n",
      " 'ZIP_CODE': 'ZIP_CODE'}\n",
      "\n",
      "Count per entity after alignment:\n",
      "[('O', 1796), ('PERSON', 433), ('DATE_TIME', 331), ('PHONE_NUMBER', 5),\n",
      " ('LOCATION', 2), ('PATIENT_ID', 1), ('MEDICAL_CONDITION', 1), ('DRUG', 1),\n",
      " ('PROCEDURE', 1)]\n"
     ]
    }
   ],
   "source": [
    "from presidio_evaluator.models import  PresidioAnalyzerWrapper\n",
    "\n",
    "entities_mapping=PresidioAnalyzerWrapper.presidio_entities_map # default mapping\n",
    "\n",
    "print(\"Using this mapping between the dataset and Presidio's entities:\")\n",
    "pprint(entities_mapping, compact=True)\n",
    "\n",
    "\n",
    "dataset = Evaluator.align_entity_types(\n",
    "    dataset, \n",
    "    entities_mapping=entities_mapping, \n",
    "    allow_missing_mappings=True\n",
    ")\n",
    "new_entity_counts = get_entity_counts(dataset)\n",
    "print(\"\\nCount per entity after alignment:\")\n",
    "pprint(new_entity_counts.most_common(), compact=True)\n",
    "\n",
    "dataset_entities = list(new_entity_counts.values())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16dbf6d6-a554-4602-8907-589786d47a12",
   "metadata": {},
   "source": [
    "## 5. Set up the Evaluator object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29d39ff1-4f14-4e32-ae84-ecc6c739f829",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-19T19:05:53.900080Z",
     "start_time": "2024-09-19T19:05:53.838844Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------\n",
      "Entities supported by this Presidio Analyzer instance:\n",
      "MEDICAL_CONDITION, DURATION, DOSAGE, LAB_TEST, VACCINE, CRYPTO, MEDICAL_LICENSE, LOCATION, EMAIL_ADDRESS, DRUG, US_BANK_NUMBER, US_PASSPORT, NRP, IBAN_CODE, US_DRIVER_LICENSE, ALLERGY, PROCEDURE, FREQUENCY, PERSON, DATE_TIME, ANATOMY, HOSPITAL, US_SSN, SYMPTOM, UK_NHS, URL, PHONE_NUMBER, US_ITIN, CREDIT_CARD, MEDICAL_DEVICE, IP_ADDRESS\n"
     ]
    }
   ],
   "source": [
    "# Set up the experiment tracker to log the experiment for reproducibility\n",
    "experiment = get_experiment_tracker()\n",
    "\n",
    "# Create the evaluator object\n",
    "evaluator = Evaluator(model=analyzer_engine)\n",
    "\n",
    "\n",
    "# Track model and dataset params\n",
    "params = {\"dataset_name\": dataset_name, \n",
    "          \"model_name\": evaluator.model.name}\n",
    "params.update(evaluator.model.to_log())\n",
    "experiment.log_parameters(params)\n",
    "experiment.log_dataset_hash(dataset)\n",
    "experiment.log_parameter(\"entity_mappings\", json.dumps(entities_mapping))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7d6626-d094-4dfd-8f37-c0443edf00dc",
   "metadata": {},
   "source": [
    "## 6. Run experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf65af8f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-19T19:06:04.563192Z",
     "start_time": "2024-09-19T19:05:59.219544Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model PresidioAnalyzerWrapper on dataset...\n",
      "Finished running model on dataset\n",
      "saving experiment data to c:\\projects\\presidio\\presidio-research\\notebooks\\experiment_20250804-134853.json\n",
      "CPU times: total: 1.77 s\n",
      "Wall time: 1.82 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "## Run experiment\n",
    "\n",
    "evaluation_results = evaluator.evaluate_all(dataset)\n",
    "results = evaluator.calculate_score(evaluation_results)\n",
    "\n",
    "# Track experiment results\n",
    "experiment.log_metrics(results.to_log())\n",
    "entities, confmatrix = results.to_confusion_matrix()\n",
    "experiment.log_confusion_matrix(matrix=confmatrix, \n",
    "                                labels=entities)\n",
    "\n",
    "# end experiment\n",
    "experiment.end()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c7518b-132c-4bc4-8155-1634ac4173bc",
   "metadata": {},
   "source": [
    "## 7. Evaluate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b4d662d-596c-4a69-b3c9-1edcda20cc5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-19T19:06:07.152556Z",
     "start_time": "2024-09-19T19:06:04.567921Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\nImage export using the \"kaleido\" engine requires the kaleido package,\nwhich can be installed using pip:\n    $ pip install -U kaleido\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Path of the directory to save the plots\u001b[39;00m\n\u001b[32m      8\u001b[39m output_folder = Path(Path.cwd().parent, \u001b[33m\"\u001b[39m\u001b[33mplotter_output\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[43mplotter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mplot_scores\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_folder\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\projects\\presidio\\presidio-research\\presidio_evaluator\\evaluation\\plotter.py:95\u001b[39m, in \u001b[36mPlotter.plot_scores\u001b[39m\u001b[34m(self, output_folder)\u001b[39m\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m fig, file_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(figs, fig_names):\n\u001b[32m     94\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m output_folder \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msave_fig_to_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_folder\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mscores-\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mfile_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     96\u001b[39m         fig.show()\n\u001b[32m     97\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\projects\\presidio\\presidio-research\\presidio_evaluator\\evaluation\\plotter.py:324\u001b[39m, in \u001b[36mPlotter.save_fig_to_file\u001b[39m\u001b[34m(self, fig, output_folder, file_name)\u001b[39m\n\u001b[32m    320\u001b[39m     fig.write_html(\n\u001b[32m    321\u001b[39m         Path(output_folder, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.model_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.save_as\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    322\u001b[39m     )\n\u001b[32m    323\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.save_as \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m324\u001b[39m     \u001b[43mfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite_image\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    325\u001b[39m \u001b[43m        \u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m-\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mfile_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m.\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msave_as\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    326\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    328\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    329\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33msave_as must be either \u001b[39m\u001b[33m'\u001b[39m\u001b[33mhtml\u001b[39m\u001b[33m'\u001b[39m\u001b[33m or a valid image format (e.g., \u001b[39m\u001b[33m'\u001b[39m\u001b[33mpng\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[33msvg\u001b[39m\u001b[33m'\u001b[39m\u001b[33m).\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    330\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\projects\\presidio\\presidio-research\\.venv\\Lib\\site-packages\\plotly\\basedatatypes.py:3835\u001b[39m, in \u001b[36mBaseFigure.write_image\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   3775\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3776\u001b[39m \u001b[33;03mConvert a figure to a static image and write it to a file or writeable\u001b[39;00m\n\u001b[32m   3777\u001b[39m \u001b[33;03mobject\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   3831\u001b[39m \u001b[33;03mNone\u001b[39;00m\n\u001b[32m   3832\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3833\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplotly\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mio\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpio\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3835\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite_image\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\projects\\presidio\\presidio-research\\.venv\\Lib\\site-packages\\plotly\\io\\_kaleido.py:266\u001b[39m, in \u001b[36mwrite_image\u001b[39m\u001b[34m(fig, file, format, scale, width, height, validate, engine)\u001b[39m\n\u001b[32m    250\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    251\u001b[39m \u001b[38;5;250m                \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    252\u001b[39m \u001b[33;03mCannot infer image type from output path '{file}'.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    260\u001b[39m                 )\n\u001b[32m    261\u001b[39m             )\n\u001b[32m    263\u001b[39m     \u001b[38;5;66;03m# Request image\u001b[39;00m\n\u001b[32m    264\u001b[39m     \u001b[38;5;66;03m# -------------\u001b[39;00m\n\u001b[32m    265\u001b[39m     \u001b[38;5;66;03m# Do this first so we don't create a file if image conversion fails\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m266\u001b[39m     img_data = \u001b[43mto_image\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    270\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheight\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    272\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    273\u001b[39m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    274\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    276\u001b[39m     \u001b[38;5;66;03m# Open file\u001b[39;00m\n\u001b[32m    277\u001b[39m     \u001b[38;5;66;03m# ---------\u001b[39;00m\n\u001b[32m    278\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    279\u001b[39m         \u001b[38;5;66;03m# We previously failed to make sense of `file` as a pathlib object.\u001b[39;00m\n\u001b[32m    280\u001b[39m         \u001b[38;5;66;03m# Attempt to write to `file` as an open file descriptor.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\projects\\presidio\\presidio-research\\.venv\\Lib\\site-packages\\plotly\\io\\_kaleido.py:132\u001b[39m, in \u001b[36mto_image\u001b[39m\u001b[34m(fig, format, width, height, scale, validate, engine)\u001b[39m\n\u001b[32m    130\u001b[39m     \u001b[38;5;66;03m# Raise informative error message if Kaleido is not installed\u001b[39;00m\n\u001b[32m    131\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m scope \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m132\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    133\u001b[39m \u001b[38;5;250m            \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    134\u001b[39m \u001b[33;03mImage export using the \"kaleido\" engine requires the kaleido package,\u001b[39;00m\n\u001b[32m    135\u001b[39m \u001b[33;03mwhich can be installed using pip:\u001b[39;00m\n\u001b[32m    136\u001b[39m \u001b[33;03m    $ pip install -U kaleido\u001b[39;00m\n\u001b[32m    137\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    138\u001b[39m         )\n\u001b[32m    140\u001b[39m     \u001b[38;5;66;03m# Validate figure\u001b[39;00m\n\u001b[32m    141\u001b[39m     \u001b[38;5;66;03m# ---------------\u001b[39;00m\n\u001b[32m    142\u001b[39m     fig_dict = validate_coerce_fig_to_dict(fig, validate)\n",
      "\u001b[31mValueError\u001b[39m: \nImage export using the \"kaleido\" engine requires the kaleido package,\nwhich can be installed using pip:\n    $ pip install -U kaleido\n"
     ]
    }
   ],
   "source": [
    "# Plot output\n",
    "plotter = Plotter(results=results, \n",
    "                  model_name = evaluator.model.name, \n",
    "                  save_as=\"png\",\n",
    "                  beta = 2) \n",
    "\n",
    "# Path of the directory to save the plots\n",
    "output_folder = Path(Path.cwd().parent, \"plotter_output\")\n",
    "plotter.plot_scores(output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c79050-c4aa-487d-b4e3-ade06f0a6340",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint({\"PII F\":results.pii_f, \"PII recall\": results.pii_recall, \"PII precision\": results.pii_precision})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070f8287",
   "metadata": {},
   "source": [
    "## 8. Error analysis\n",
    "\n",
    "Now let's look into results to understand what's behind the metrics we're getting.\n",
    "Note that evaluation is never perfect. Some things to consider:\n",
    "1. There's often a mismatch between the annotated span and the predicted span, which isn't necessarily a mistake. For example: `<Southern France>` compared with `Southern <France>`. In the second text, the word `Southern` was not annotated/predicted as part of the entity, but that's not necessarily an error.\n",
    "2. Token based evaluation (which is used here) counts the number of true positive / false positive / false negative tokens. Some entities might be broken into more tokens than others. For example, the phone number `222-444-1234` could be broken into five different tokens, whereas `Krishna` would be broken into one token, resulting in phone numbers having more influence on metrics than names.\n",
    "3. The synthetic dataset used here isn't representative of a real dataset. Consider using more realistic datasets for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe3b38d440148cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-19T18:34:25.363401Z",
     "start_time": "2024-09-19T18:34:24.800792Z"
    }
   },
   "outputs": [],
   "source": [
    "plotter.plot_confusion_matrix(entities=entities, confmatrix=confmatrix, output_folder=output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a408f03e-a014-4631-923f-00cc9d6e08e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter.plot_most_common_tokens(output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819eb905",
   "metadata": {},
   "source": [
    "### 7a. False positives\n",
    "#### Most common false positive tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640037af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-19T18:14:13.476011Z",
     "start_time": "2024-09-19T18:14:13.408070Z"
    }
   },
   "outputs": [],
   "source": [
    "ModelError.most_common_fp_tokens(results.model_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2057bb-0af7-4c28-8fa7-9dcf68d4436a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-19T18:14:13.562787Z",
     "start_time": "2024-09-19T18:14:13.501083Z"
    }
   },
   "source": [
    "#### More FP analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2612275-830f-47ad-aa32-61879b79c57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fps_df = ModelError.get_fps_dataframe(results.model_errors, entity=[\"PERSON\"])\n",
    "fps_df[[\"full_text\", \"token\", \"annotation\", \"prediction\"]].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0852513",
   "metadata": {},
   "source": [
    "### 7b. False negatives (FN)\n",
    "\n",
    "#### Most common false negative examples + a few samples with FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afae40fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-19T18:14:13.661044Z",
     "start_time": "2024-09-19T18:14:13.595728Z"
    }
   },
   "outputs": [],
   "source": [
    "ModelError.most_common_fn_tokens(results.model_errors, n=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ed6416",
   "metadata": {},
   "source": [
    "#### More FN analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abfcbe9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-19T18:14:13.745681Z",
     "start_time": "2024-09-19T18:14:13.682894Z"
    }
   },
   "outputs": [],
   "source": [
    "fns_df = ModelError.get_fns_dataframe(results.model_errors, entity=[\"PHONE_NUMBER\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae73b2e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-19T18:14:13.815256Z",
     "start_time": "2024-09-19T18:14:13.750819Z"
    }
   },
   "outputs": [],
   "source": [
    "fns_df[[\"full_text\", \"token\", \"annotation\", \"prediction\"]].head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
